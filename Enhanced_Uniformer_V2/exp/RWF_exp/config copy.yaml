TRAIN:
  ENABLE: False
  DATASET: Vioguard_eccv  # Must match the class name in slowfast/datasets/vioguard_eccv.py
  BATCH_SIZE: 16
  EVAL_PERIOD: 1
  CHECKPOINT_PERIOD: 1    # Save every 5 epochs to save disk space
  AUTO_RESUME: False
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /vol/bitbucket/sna21/CUENet/best_checkpoints/baseline/best-001.pyth #/vol/bitbucket/sna21/CUENet/best_checkpoints/ablation_rgb_pose/checkpoint_epoch_00159.pyth 
DATA:
  USE_OFFSET_SAMPLING: True
  DECODING_BACKEND: decord
  NUM_FRAMES: 16 
  SAMPLING_RATE: 4 
  TRAIN_JITTER_SCALES: [384, 480]
  TRAIN_CROP_SIZE: 192
  TEST_CROP_SIZE: 256
  INPUT_CHANNEL_NUM: [3]
  PATH_TO_DATA_DIR: /vol/bitbucket/sna21/dataset/VioGuard
  PATH_PREFIX: /vol/bitbucket/sna21/dataset/VioGuard
  CAPTION_JSON_PATH: /vol/bitbucket/sna21/dataset/VioGuard/video_llm_captions.json
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  # Note: POSE_PATH_PREFIX is handled inside the dataset loader logic now
  POSE_PATH_PREFIX: /vol/bitbucket/sna21/dataset/VioGuard/multi/pose_outputs
DISTILLATION:
  ENABLE: False # Disable Distillation for Teacher Training
  TEACHER_CHECKPOINT: ""
  FEAT_DIM: 128
  NCE_K: 16384
  NCE_T: 0.07
  NCE_M: 0.5
  BETA: 0.8
UNIFORMERV2:
  BACKBONE: 'uniformerv2_l14_336' # Ensure this key exists in your model_zoo
  N_LAYERS: 4
  N_DIM: 1024
  N_HEAD: 16
  MLP_FACTOR: 4.0
  BACKBONE_DROP_PATH_RATE: 0.0
  DROP_PATH_RATE: 0.0
  MLP_DROPOUT: [0.5, 0.5, 0.5, 0.5]
  CLS_DROPOUT: 0.5
  RETURN_LIST: [20, 21, 22, 23]
  NO_LMHRA: True
  TEMPORAL_DOWNSAMPLE: False
  DELETE_SPECIAL_HEAD: True
  # Set Pretrain to empty string if loading via CHECKPOINT_FILE_PATH in TRAIN
  PRETRAIN: "" 
MODEL:
  NUM_CLASSES: 2
  ARCH: uniformerv2 
  MODEL_NAME: FusionCUENet_eccv # Must match the class name in eccv_architecture.py
  LOSS_FUNC: dynamic_ce_tloss 
  DROPOUT_RATE: 0.5
  USE_CHECKPOINT: True
  CHECKPOINT_NUM: [24]
  FREEZE_TEXT_ENCODER: True # Handled internally by SoftPromptTextEncoder, but good to keep explicit
  USE_RGB: False   # CHANGED TO TRUE: Essential for Fusion Model
  USE_POSE: False
  USE_TEXT: True
  # Enable or disable LoRA parameter-efficient tuning (True/False)
  ENABLE_LORA: False
  # Enable or disable soft prompting for the text encoder
  SOFT_PROMPT: True
  # Number of soft prompt vectors (used when SOFT_PROMPT=True)
  SOFT_PROMPT_N_CTX: 16
  POSE_USE_VELOCITY: False
SOLVER:
  BASE_LR: 0.005  # Increased LR for LoRA (Standard for Parameter-Efficient Tuning)
  LR_POLICY: cosine
  MAX_EPOCH: 100
  MOMENTUM: 0.9
  WEIGHT_DECAY: 1e-4
  WARMUP_EPOCHS: 5.0
  WARMUP_START_LR: 1e-5
  OPTIMIZING_METHOD: sgd
TEST:
  ENABLE: True
  DATASET: Vioguard_eccv
  BATCH_SIZE: 1
  NUM_SPATIAL_CROPS: 1
  NUM_ENSEMBLE_VIEWS: 1
  CHECKPOINT_FILE_PATH: "" #/vol/bitbucket/sna21/CUENet/best_checkpoints/eccv_lora_rgb/checkpoint_epoch_00022.pyth
NUM_GPUS: 1
NUM_SHARDS: 1
RNG_SEED: 0
OUTPUT_DIR: /vol/bitbucket/sna21/checkpoints/eccv_text_with_soft_num9